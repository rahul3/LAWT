{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a18f65e-59ef-4637-b309-2d7acb0c3e4f",
   "metadata": {},
   "source": [
    "## Neural Network Approach For Functions Of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c09a2d2-4877-4a50-853b-7c3038303eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd27c9e-0da7-482b-8b09-4bdc54360664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = datetime.datetime.strftime(datetime.datetime.now(),'%Y%M%d%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44205ff2-6f0c-43ae-bbab-8f01acca0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving results\n",
    "save_dir = os.path.join(os.getcwd(), 'matrix_exp_results', ID)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d344e133-2ad1-43c6-8199-051ebe1c357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee4db68-389c-4782-928e-0d6aa70cc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class MatrixExponentialNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MatrixExponentialNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6930299-80bc-49a0-8170-8bd411528c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5969f2-2ad8-41c7-82cb-3214c4278191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input size (5x5 matrix flattened)\n",
    "input_size = 5 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c42f91-27a8-4341-8a6c-25af02fe0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "distribution = \"gaussian\" # or uniform\n",
    "coeff_lower = 0 \n",
    "coeff_upper = 10\n",
    "\n",
    "lr = 1e-5 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c99e62-9299-40ad-beb0-818c3d5dc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to GPU\n",
    "model = MatrixExponentialNet(input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562db912-e690-45fd-9e8d-e1d8ef91d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixLoss(nn.Module):\n",
    "    def __init__(self, dim=5):\n",
    "        super(MatrixLoss, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        e = pred - target\n",
    "        e_reshaped = e.view(-1, self.dim, self.dim)\n",
    "        \n",
    "        max_abs = torch.max(torch.abs(e_reshaped).view(e_reshaped.size(0), -1), dim=1)[0]\n",
    "        sum_abs = torch.sum(torch.abs(e_reshaped), dim=(1,2)) / self.dim\n",
    "        trace = torch.sum(e_reshaped ** 2, dim=(1,2)) / self.dim\n",
    "        \n",
    "        loss = max_abs + sum_abs + trace\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aee4c37-28c9-4fbd-bd59-5541252df010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = MatrixLoss(dim=5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb4f07e-f323-4909-ba56-baffa113d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute matrix exponential\n",
    "def matrix_exponential(batch_matrices):\n",
    "    return np.array([expm(A) for A in batch_matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1fbace4-69ec-4f72-b469-86abd89a09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 100000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4f019f-7066-4062-b731-a22ff459cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store loss values for plotting\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4106285c-1ba1-4c22-848a-fc0c98bc0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee45a1a-def1-48f6-a8a8-efc284f8acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000], Train Loss: 180,620,623,385,460,736, Val Loss: 2,265,617,797,218,304\n",
      "Epoch [2000/100000], Train Loss: 1,010,911,552,733,184, Val Loss: 17,426,043,240,389,279,744\n",
      "Epoch [3000/100000], Train Loss: 10,054,729,271,290,626,048, Val Loss: 10,001,240,444,370,944\n",
      "Epoch [4000/100000], Train Loss: 191,239,156,662,272, Val Loss: 231,681,909,019,639,808\n",
      "Epoch [5000/100000], Train Loss: 121,470,763,281,678,336, Val Loss: 19,240,031,851,905,024\n",
      "Epoch [6000/100000], Train Loss: 11,191,860,139,655,168, Val Loss: 479,284,426,702,848\n",
      "Epoch [7000/100000], Train Loss: 718,450,170,986,416,308,224, Val Loss: 4,728,012,205,457,408\n",
      "Epoch [8000/100000], Train Loss: 2,673,130,199,842,816, Val Loss: 221,877,473,640,448\n",
      "Epoch [9000/100000], Train Loss: 862,175,033,533,923,328, Val Loss: 52,518,495,023,267,840\n",
      "Epoch [10000/100000], Train Loss: 615,916,246,029,828,096, Val Loss: 603,302,580,453,376\n",
      "Epoch [11000/100000], Train Loss: 443,578,346,815,619,072, Val Loss: 4,392,168,796,819,816,448\n",
      "Epoch [12000/100000], Train Loss: 480,886,288,174,546,944, Val Loss: 2,342,653,404,381,184\n",
      "Epoch [13000/100000], Train Loss: 968,843,690,246,144, Val Loss: 445,282,761,637,363,712\n",
      "Epoch [14000/100000], Train Loss: 10,649,954,418,688, Val Loss: 39,219,072,956,628,992\n",
      "Epoch [15000/100000], Train Loss: 6,634,138,018,775,040, Val Loss: 5,800,752,840,704\n",
      "Epoch [16000/100000], Train Loss: 3,716,123,277,476,581,343,232, Val Loss: 8,214,500,226,367,488\n",
      "Epoch [17000/100000], Train Loss: 994,184,265,728,000, Val Loss: 2,314,109,412,509,220,864\n",
      "Epoch [18000/100000], Train Loss: 4,228,068,348,526,592, Val Loss: 38,268,111,362,719,744\n",
      "Epoch [19000/100000], Train Loss: 1,512,390,592,036,864, Val Loss: 1,947,363,941,810,176\n",
      "Epoch [20000/100000], Train Loss: 51,182,987,552,600,621,056, Val Loss: 5,319,785,185,280\n",
      "Epoch [21000/100000], Train Loss: 9,774,517,710,749,696, Val Loss: 1,865,744,530,800,640\n",
      "Epoch [22000/100000], Train Loss: 1,037,868,058,120,552,448, Val Loss: 3,113,269,053,095,936\n",
      "Epoch [23000/100000], Train Loss: 873,389,921,140,736, Val Loss: 546,685,736,905,080,832\n",
      "Epoch [24000/100000], Train Loss: 2,240,542,033,313,792, Val Loss: 670,566,533,038,080\n",
      "Epoch [25000/100000], Train Loss: 1,861,132,004,360,192, Val Loss: 70,745,936,795,533,312\n",
      "Epoch [26000/100000], Train Loss: 7,851,766,993,341,885,972,480, Val Loss: 116,905,968,960,274,432\n",
      "Epoch [27000/100000], Train Loss: 33,022,614,117,023,744, Val Loss: 19,169,719,148,460,638,208\n",
      "Epoch [28000/100000], Train Loss: 326,211,188,293,632, Val Loss: 23,273,748,299,776\n",
      "Epoch [29000/100000], Train Loss: 261,915,125,219,328, Val Loss: 30,860,516,842,799,104\n",
      "Epoch [30000/100000], Train Loss: 3,493,393,357,659,439,104, Val Loss: 102,033,273,126,912\n",
      "Epoch [31000/100000], Train Loss: 65,595,377,654,431,744, Val Loss: 2,646,325,845,819,392\n",
      "Epoch [32000/100000], Train Loss: 11,088,948,428,275,712, Val Loss: 189,731,417,251,381,248\n",
      "Epoch [33000/100000], Train Loss: 41,105,617,846,272, Val Loss: 12,202,577,613,553,664\n",
      "Epoch [34000/100000], Train Loss: 39,445,254,524,370,944, Val Loss: 164,551,415,564,337,152\n",
      "Epoch [35000/100000], Train Loss: 221,726,545,805,312, Val Loss: 226,368,587,797,889,024\n",
      "Epoch [36000/100000], Train Loss: 219,359,063,731,863,552, Val Loss: 6,046,433,484,472,320\n",
      "Epoch [37000/100000], Train Loss: 1,560,235,722,407,936, Val Loss: 2,179,331,098,935,296\n",
      "Epoch [38000/100000], Train Loss: 2,798,479,088,812,032, Val Loss: 7,949,043,867,058,176\n",
      "Epoch [39000/100000], Train Loss: 353,287,688,893,235,200, Val Loss: 2,751,889,587,834,978,304\n",
      "Epoch [40000/100000], Train Loss: 9,342,349,511,491,584, Val Loss: 321,998,302,386,061,312\n",
      "Epoch [41000/100000], Train Loss: 6,265,570,768,977,920, Val Loss: 5,877,492,499,494,090,047,488\n",
      "Epoch [42000/100000], Train Loss: 26,788,338,571,413,553,152, Val Loss: 16,625,208,131,584\n",
      "Epoch [43000/100000], Train Loss: 197,873,941,610,496, Val Loss: 821,788,640,542,720\n",
      "Epoch [44000/100000], Train Loss: 1,679,035,591,557,120, Val Loss: 5,958,508,524,601,344\n",
      "Epoch [45000/100000], Train Loss: 323,188,470,841,344, Val Loss: 108,472,886,573,924,352\n",
      "Epoch [46000/100000], Train Loss: 2,001,884,806,421,413,888, Val Loss: 346,458,066,780,160\n",
      "Epoch [47000/100000], Train Loss: 5,644,049,809,670,144, Val Loss: 1,272,534,076,057,714,688\n",
      "Epoch [48000/100000], Train Loss: 5,577,478,353,453,056, Val Loss: 1,297,434,853,330,911,232\n",
      "Epoch [49000/100000], Train Loss: 671,780,465,278,976, Val Loss: 984,254,368,448,512\n",
      "Epoch [50000/100000], Train Loss: 30,505,396,061,863,936, Val Loss: 764,362,685,285,400,576\n",
      "Epoch [51000/100000], Train Loss: 8,610,564,393,664,512, Val Loss: 16,540,944,480,337,920\n",
      "Epoch [52000/100000], Train Loss: 208,873,218,637,824, Val Loss: 83,814,926,960,434,348,032\n",
      "Epoch [53000/100000], Train Loss: 4,097,559,054,203,748,352, Val Loss: 17,579,851,722,975,608,832\n",
      "Epoch [54000/100000], Train Loss: 268,497,256,250,062,405,632, Val Loss: 1,691,378,656,477,184\n",
      "Epoch [55000/100000], Train Loss: 47,558,248,366,080, Val Loss: 557,906,084,757,504\n",
      "Epoch [56000/100000], Train Loss: 118,109,620,928,512, Val Loss: 14,137,121,077,985,280\n",
      "Epoch [57000/100000], Train Loss: 3,455,392,457,687,040, Val Loss: 3,986,114,855,567,360\n",
      "Epoch [58000/100000], Train Loss: 408,747,021,038,518,272, Val Loss: 81,675,274,236,557,508,214,784\n",
      "Epoch [59000/100000], Train Loss: 42,566,269,819,420,672, Val Loss: 2,292,702,397,857,792\n",
      "Epoch [60000/100000], Train Loss: 511,165,163,634,688, Val Loss: 4,629,349,290,475,520\n",
      "Epoch [61000/100000], Train Loss: 2,335,958,357,820,571,648, Val Loss: 43,978,420,706,607,104\n",
      "Epoch [62000/100000], Train Loss: 343,851,659,165,696, Val Loss: 7,885,392,829,688,578,048\n",
      "Epoch [63000/100000], Train Loss: 8,512,851,680,067,321,856, Val Loss: 2,614,964,799,930,368\n",
      "Epoch [64000/100000], Train Loss: 1,225,246,279,970,324,480, Val Loss: 199,918,358,122,987,520\n",
      "Epoch [65000/100000], Train Loss: 12,463,840,474,169,344, Val Loss: 54,192,561,606,098,944\n",
      "Epoch [66000/100000], Train Loss: 28,034,857,959,424, Val Loss: 3,735,409,885,706,190,848\n",
      "Epoch [67000/100000], Train Loss: 176,984,410,889,056,681,984, Val Loss: 75,426,471,895,629,824\n",
      "Epoch [68000/100000], Train Loss: 103,168,619,143,233,536, Val Loss: 175,461,057,429,504\n",
      "Epoch [69000/100000], Train Loss: 10,901,698,471,329,267,712, Val Loss: 9,049,517,567,508,480\n",
      "Epoch [70000/100000], Train Loss: 1,323,318,996,420,595,286,016, Val Loss: 1,939,472,953,016,057,856\n",
      "Epoch [71000/100000], Train Loss: 381,009,400,954,880, Val Loss: 29,475,041,747,624,110,587,904\n",
      "Epoch [72000/100000], Train Loss: 635,238,145,327,104, Val Loss: 1,649,127,184,138,240\n",
      "Epoch [73000/100000], Train Loss: 5,474,849,573,044,224, Val Loss: 977,013,053,587,456\n",
      "Epoch [74000/100000], Train Loss: 24,398,391,718,768,017,408, Val Loss: 2,379,499,123,507,200\n",
      "Epoch [75000/100000], Train Loss: 1,002,039,303,498,366,976, Val Loss: 1,073,886,376,493,056\n",
      "Epoch [76000/100000], Train Loss: 114,115,888,545,792, Val Loss: 955,312,597,106,688\n",
      "Epoch [77000/100000], Train Loss: 8,705,729,888,256, Val Loss: 436,755,861,864,448\n",
      "Epoch [78000/100000], Train Loss: 105,658,326,188,032, Val Loss: 18,696,340,766,720\n",
      "Epoch [79000/100000], Train Loss: 243,530,521,198,460,928, Val Loss: 293,699,965,463,560,192\n",
      "Epoch [80000/100000], Train Loss: 2,056,267,937,873,920, Val Loss: 199,407,531,892,670,464\n",
      "Epoch [81000/100000], Train Loss: 157,539,501,080,576, Val Loss: 268,094,126,359,052,288\n",
      "Epoch [82000/100000], Train Loss: 124,229,680,889,856, Val Loss: 849,975,539,706,888,192\n",
      "Epoch [83000/100000], Train Loss: 3,953,196,347,162,624, Val Loss: 46,420,558,490,005,143,552\n",
      "Epoch [84000/100000], Train Loss: 50,150,958,725,857,280, Val Loss: 17,051,957,541,732,352\n",
      "Epoch [85000/100000], Train Loss: 43,038,905,200,541,696, Val Loss: 29,503,094,576,381,952\n",
      "Epoch [86000/100000], Train Loss: 13,914,142,482,104,320, Val Loss: 7,462,646,336,978,944\n",
      "Epoch [87000/100000], Train Loss: 55,218,635,031,189,651,456, Val Loss: 568,423,083,933,696\n",
      "Epoch [88000/100000], Train Loss: 192,091,388,903,424, Val Loss: 10,351,524,843,022,712,832\n",
      "Epoch [89000/100000], Train Loss: 7,475,609,622,020,096, Val Loss: 1,731,616,326,025,216\n",
      "Epoch [90000/100000], Train Loss: 19,579,745,075,200, Val Loss: 2,245,158,720,503,808\n",
      "Epoch [91000/100000], Train Loss: 71,449,775,702,016, Val Loss: 17,881,880,970,055,909,376\n",
      "Epoch [92000/100000], Train Loss: 446,185,663,889,408, Val Loss: 331,243,648,987,430,912\n",
      "Epoch [93000/100000], Train Loss: 2,750,087,692,288,000, Val Loss: 13,776,834,525,134,848\n",
      "Epoch [94000/100000], Train Loss: 608,796,984,475,648, Val Loss: 365,542,536,258,781,184\n",
      "Epoch [95000/100000], Train Loss: 6,263,882,309,959,680, Val Loss: 107,936,989,416,909,701,120\n",
      "Epoch [96000/100000], Train Loss: 5,927,945,000,452,096, Val Loss: 592,397,255,835,648\n",
      "Epoch [97000/100000], Train Loss: 192,853,446,158,712,832, Val Loss: 1,307,783,852,982,272\n",
      "Epoch [98000/100000], Train Loss: 128,472,999,526,400, Val Loss: 7,925,884,866,527,232\n",
      "Epoch [99000/100000], Train Loss: 73,501,469,835,264, Val Loss: 32,689,350,424,657,920\n",
      "Epoch [100000/100000], Train Loss: 217,389,752,909,824, Val Loss: 1,414,354,473,844,736\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Generate random 5x5 matrices\n",
    "    if distribution == \"gaussian\":\n",
    "        A = np.random.randn(batch_size, 5, 5)\n",
    "        A = np.array(coeff_upper / math.sqrt(3.0) * A)\n",
    "    elif distribution == \"uniform\":\n",
    "        A = np.random.rand(batch_size, 5, 5)\n",
    "        A = np.array(max_coeff * (2 * A - 1))\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported distribution\")\n",
    "\n",
    "    \n",
    "    # Calculate exp(A)\n",
    "    A_exp = matrix_exponential(A)\n",
    "    \n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    A_tensor = torch.FloatTensor(A).view(batch_size, -1).to(device)\n",
    "    A_exp_tensor = torch.FloatTensor(A_exp).view(batch_size, -1).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(A_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, A_exp_tensor)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation step\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if distribution == \"gaussian\":\n",
    "                A_val = np.random.randn(batch_size, 5, 5)\n",
    "                A_val = np.array(coeff_upper / math.sqrt(3.0) * A_val)\n",
    "            elif distribution == \"uniform\":\n",
    "                A_val = np.random.rand(batch_size, 5, 5)\n",
    "                A_val = np.array(max_coeff * (2 * A_val - 1))\n",
    "            else:\n",
    "                raise TypeError(\"Unsupported distribution\")\n",
    "            # A_val = np.random.randn(batch_size, 5, 5)\n",
    "            A_exp_val = matrix_exponential(A_val)\n",
    "            A_val_tensor = torch.FloatTensor(A_val).view(batch_size, -1).to(device)\n",
    "            A_exp_val_tensor = torch.FloatTensor(A_exp_val).view(batch_size, -1).to(device)\n",
    "            val_output = model(A_val_tensor)\n",
    "            val_loss = criterion(val_output, A_exp_val_tensor)\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "        # print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():,.0f}, Val Loss: {val_loss.item():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06dec0b-af74-41de-8f90-bd21bde35fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, 'matrix_exp_model.pth'))\n",
    "\n",
    "# Save loss lists\n",
    "with open(os.path.join(save_dir, 'losses.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Epoch', 'Train Loss', 'Validation Loss'])\n",
    "    for i, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses)):\n",
    "        writer.writerow([i*100, train_loss, val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af594b89-db17-4df0-b487-6f9f2596515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 288444631385546686464.0000\n",
      "\n",
      "Example 1:\n",
      "Input matrix A:\n",
      "[[-7.23298373  4.11937364  0.62292664 10.87093629  2.23151741]\n",
      " [-9.34260493  2.45402435 -8.81392734 11.6679538   0.55533743]\n",
      " [ 1.56310919  3.59035193  0.21397936 -0.89488649  7.31673767]\n",
      " [-1.98572003 -2.0223425   2.89372622 -1.26827436  2.78360117]\n",
      " [-4.56090561 -1.6887625  -6.67626007 -8.77067973 11.271082  ]]\n",
      "Actual exp(A):\n",
      "[[ -27.60059757   -3.45730879  -15.03111203  -28.43807304   84.83178887]\n",
      " [  52.86914709  -19.34610802  -31.17581161  -40.07877875 -129.02466706]\n",
      " [ -59.57515951  -44.54067321 -119.18571563 -198.83272412  232.43273761]\n",
      " [ -41.2853674     2.74294756   -4.092044    -13.7943263   116.83385837]\n",
      " [ -23.97514238  -93.78521651 -224.13214111 -359.25119788  194.35281548]]\n",
      "Predicted exp(A):\n",
      "[[153.07974      5.3753395    4.208857    10.757149    -3.3333933 ]\n",
      " [ -3.9509356  128.31146    -18.850147   -25.016426     4.0324264 ]\n",
      " [ 12.163473     2.704027   150.36699     -0.15654051  -9.265894  ]\n",
      " [ 29.056732    15.793774   -18.640957   152.23584      9.975743  ]\n",
      " [ -4.9772153  -32.606014   -14.243397    20.544352   147.81447   ]]\n",
      "\n",
      "Example 2:\n",
      "Input matrix A:\n",
      "[[-8.12487679e+00  9.52960564e+00 -1.68241355e+00 -9.82567196e+00\n",
      "   4.09068925e-03]\n",
      " [-4.31941290e+00 -2.84539900e+00  8.57413041e-01 -4.89060031e+00\n",
      "  -1.06947726e+00]\n",
      " [-8.86451866e+00  1.09583566e+01 -6.23748910e+00  4.95512680e+00\n",
      "  -3.48754135e-01]\n",
      " [ 2.58201822e+00 -2.45321592e+00 -3.06180786e+00 -3.01388110e+00\n",
      "   7.21432351e+00]\n",
      " [ 4.40259778e+00 -2.14436197e+00 -3.02307188e+00  1.08742243e+01\n",
      "   4.68016998e-02]]\n",
      "Actual exp(A):\n",
      "[[  8.37600679  -5.35328814  -5.47600813   9.11899241  11.22200266]\n",
      " [  5.01267979  -0.78248328  -3.04099186   0.81638841   4.87797691]\n",
      " [  0.72206407   5.13365737   0.07086082  -9.9249924   -3.26699618]\n",
      " [ -9.98575915   3.9504248    6.28949089  -6.20259303 -11.5251091 ]\n",
      " [-13.25893911   5.81883777   8.40560527  -9.3280539  -15.731626  ]]\n",
      "Predicted exp(A):\n",
      "[[ 96.58817      3.0542703    2.3465436    6.563676    -2.0529692 ]\n",
      " [ -2.6502326   80.654884   -11.831783   -16.35377      2.2818413 ]\n",
      " [  7.1832128    2.281039    94.7781       0.43460405  -5.8944035 ]\n",
      " [ 17.762573    10.042794   -10.747179    95.96367      6.6631985 ]\n",
      " [ -3.149293   -20.565052    -9.258624    13.269154    92.612785  ]]\n",
      "\n",
      "Example 3:\n",
      "Input matrix A:\n",
      "[[  2.52052402   0.02037913   5.81899754  -0.67613911  -1.76646987]\n",
      " [  6.45382981   2.5958953   -2.81030072  -3.53435011   4.47495296]\n",
      " [ -7.65183635   4.64365661  -0.7892912   -3.71422936  -6.59427977]\n",
      " [ -9.55048343   1.60231064 -10.92782078  -0.2208441   -1.91209612]\n",
      " [ -0.25335605  -1.03774264   3.5210257    4.72014907  -7.39589705]]\n",
      "Actual exp(A):\n",
      "[[ 1156.77685719  1148.79689881  1988.89934837 -1572.90285714\n",
      "   -431.556939  ]\n",
      " [ 1536.0278847   1522.68114816  2635.23680555 -2083.22401789\n",
      "   -572.11975988]\n",
      " [  886.24169901   879.34216466  1521.67393187 -1203.13265019\n",
      "   -330.11673793]\n",
      " [-1911.45565953 -1899.28301381 -3288.01384397  2600.55643318\n",
      "    713.13320661]\n",
      " [ -478.90794687  -476.31251831  -824.99544802   652.66330985\n",
      "    178.96218163]]\n",
      "Predicted exp(A):\n",
      "[[103.15081     3.1700258   3.3694923   6.9047136  -2.4951708]\n",
      " [ -2.5446231  87.56169   -12.919589  -17.066582    3.9679008]\n",
      " [  8.67989     1.2008376 102.39739    -1.4328072  -6.64752  ]\n",
      " [ 18.947826   10.354527  -13.721397  103.07967     5.9795375]\n",
      " [ -3.213307  -21.929722   -9.794369   13.055122   98.62206  ]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate test matrices\n",
    "    num_test = 1000\n",
    "\n",
    "    if distribution == \"gaussian\":\n",
    "        A_test = np.random.randn(num_test, 5, 5)\n",
    "        A_test = np.array(coeff_upper / math.sqrt(3.0) * A_test)\n",
    "    elif distribution == \"uniform\":\n",
    "        A_test = np.random.rand(num_test, 5, 5)\n",
    "        A_test = np.array(max_coeff * (2 * A_test - 1))\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported distributon.\")\n",
    "    \n",
    "    A_exp_test = matrix_exponential(A_test)\n",
    "    \n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    A_test_tensor = torch.FloatTensor(A_test).view(num_test, -1).to(device)\n",
    "    A_exp_test_tensor = torch.FloatTensor(A_exp_test).view(num_test, -1).to(device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    predictions = model(A_test_tensor)\n",
    "    \n",
    "    # Compute test loss\n",
    "    test_loss = criterion(predictions, A_exp_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    \n",
    "    # Compare a few results\n",
    "    for i in range(3):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(\"Input matrix A:\")\n",
    "        print(A_test[i])\n",
    "        print(\"Actual exp(A):\")\n",
    "        print(A_exp_test[i])\n",
    "        print(\"Predicted exp(A):\")\n",
    "        print(predictions[i].view(5, 5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070161c7-cec1-4d6d-9041-78ac3ac696bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data and evaluations\n",
    "with open(os.path.join(save_dir, 'test_data_and_evaluations.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Test Matrix', 'Actual exp(A)', 'Predicted exp(A)', 'Error'])\n",
    "    for i in range(num_test):\n",
    "        pred = predictions[i].cpu().numpy().flatten()\n",
    "        actual = A_exp_test[i].flatten()\n",
    "        writer.writerow([\n",
    "            A_test[i].flatten().tolist(),\n",
    "            actual.tolist(),\n",
    "            pred.tolist(),\n",
    "            (pred - actual).tolist()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b9a87d3-6aec-47d9-8089-f1abee44e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_losses)=100000\n",
      "len(val_losses)=100\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_losses)=}\\n{len(val_losses)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e6af7aa-ec5b-4d8b-beb2-4dfe387badb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "# 1. Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(range(99, len(train_losses), 1000), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91276c0f-830d-44f3-b67d-6d9dfe795b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Histogram of Errors\n",
    "errors = (predictions - A_exp_test_tensor).cpu().numpy().flatten()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(errors, bins=50)\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Errors')\n",
    "plt.savefig(os.path.join(save_dir, 'error_histogram.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bf46488-513f-4913-9336-6d81c56e81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predicted vs Actual Values\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(A_exp_test_tensor.cpu().numpy().flatten(), predictions.cpu().numpy().flatten(), alpha=0.5)\n",
    "plt.plot([A_exp_test_tensor.cpu().numpy().min(), A_exp_test_tensor.cpu().numpy().max()], \n",
    "         [A_exp_test_tensor.cpu().numpy().min(), A_exp_test_tensor.cpu().numpy().max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.savefig(os.path.join(save_dir, 'predicted_vs_actual.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ed70a78-bbf1-44be-8a0b-6756bdbe4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Example Comparison\n",
    "example_idx = 0\n",
    "actual = A_exp_test[example_idx]\n",
    "predicted = predictions[example_idx].view(5, 5).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fbb3f4b-3fbe-44d8-bdd9-2d55512f0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ac014350f70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "im1 = ax1.imshow(actual, cmap='viridis')\n",
    "ax1.set_title('Actual exp(A)')\n",
    "plt.colorbar(im1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07869f14-7e6b-45b0-91fd-4dc9c21d6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ac016fbca00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im2 = ax2.imshow(predicted, cmap='viridis')\n",
    "ax2.set_title('Predicted exp(A)')\n",
    "plt.colorbar(im2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10a85347-6dba-4150-b4d6-d2350e634b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations have been saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'example_comparison.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Visualizations have been saved as PNG files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d37e5e-001a-42c1-9729-28360ab9468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6445bdf4-adaa-4ce0-9b9a-a6f93b53730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rahulpadmanabhan/Development/ws1/masters_thesis_2/LAWT/notebooks/matrix_exp_results/202405161723781116'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c13e4f-5687-48dc-804e-31055985a772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
