{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a18f65e-59ef-4637-b309-2d7acb0c3e4f",
   "metadata": {},
   "source": [
    "## Neural Network Approach For Functions Of Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c09a2d2-4877-4a50-853b-7c3038303eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd27c9e-0da7-482b-8b09-4bdc54360664",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = datetime.datetime.strftime(datetime.datetime.now(),'%Y%M%d%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44205ff2-6f0c-43ae-bbab-8f01acca0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for saving results\n",
    "save_dir = os.path.join(os.getcwd(), 'matrix_exp_results', ID)\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d344e133-2ad1-43c6-8199-051ebe1c357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee4db68-389c-4782-928e-0d6aa70cc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class MatrixExponentialNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MatrixExponentialNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6930299-80bc-49a0-8170-8bd411528c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5969f2-2ad8-41c7-82cb-3214c4278191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input size (5x5 matrix flattened)\n",
    "input_size = 5 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c42f91-27a8-4341-8a6c-25af02fe0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "distribution = \"gaussian\" # or uniform\n",
    "coeff_lower = 0 \n",
    "coeff_upper = 10\n",
    "\n",
    "lr = 1e-5 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c99e62-9299-40ad-beb0-818c3d5dc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to GPU\n",
    "model = MatrixExponentialNet(input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562db912-e690-45fd-9e8d-e1d8ef91d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixLoss(nn.Module):\n",
    "    def __init__(self, dim=5):\n",
    "        super(MatrixLoss, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        e = pred - target\n",
    "        e_reshaped = e.view(-1, self.dim, self.dim)\n",
    "        \n",
    "        max_abs = torch.max(torch.abs(e_reshaped).view(e_reshaped.size(0), -1), dim=1)[0]\n",
    "        sum_abs = torch.sum(torch.abs(e_reshaped), dim=(1,2)) / self.dim\n",
    "        trace = torch.sum(e_reshaped ** 2, dim=(1,2)) / self.dim\n",
    "        \n",
    "        loss = max_abs + sum_abs + trace\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aee4c37-28c9-4fbd-bd59-5541252df010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = MatrixLoss(dim=5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb4f07e-f323-4909-ba56-baffa113d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute matrix exponential\n",
    "def matrix_exponential(batch_matrices):\n",
    "    return np.array([expm(A) for A in batch_matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1fbace4-69ec-4f72-b469-86abd89a09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 100000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4f019f-7066-4062-b731-a22ff459cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store loss values for plotting\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4106285c-1ba1-4c22-848a-fc0c98bc0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee45a1a-def1-48f6-a8a8-efc284f8acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/100000], Train Loss: 180,620,623,385,460,736, Val Loss: 2,265,617,797,218,304\n",
      "Epoch [2000/100000], Train Loss: 1,010,911,552,733,184, Val Loss: 17,426,043,240,389,279,744\n",
      "Epoch [3000/100000], Train Loss: 10,054,729,271,290,626,048, Val Loss: 10,001,240,444,370,944\n",
      "Epoch [4000/100000], Train Loss: 191,239,156,662,272, Val Loss: 231,681,909,019,639,808\n",
      "Epoch [5000/100000], Train Loss: 121,470,763,281,678,336, Val Loss: 19,240,031,851,905,024\n",
      "Epoch [6000/100000], Train Loss: 11,191,860,139,655,168, Val Loss: 479,284,426,702,848\n",
      "Epoch [7000/100000], Train Loss: 718,450,170,986,416,308,224, Val Loss: 4,728,012,205,457,408\n",
      "Epoch [8000/100000], Train Loss: 2,673,130,199,842,816, Val Loss: 221,877,473,640,448\n",
      "Epoch [9000/100000], Train Loss: 862,175,033,533,923,328, Val Loss: 52,518,495,023,267,840\n",
      "Epoch [10000/100000], Train Loss: 615,916,246,029,828,096, Val Loss: 603,302,580,453,376\n",
      "Epoch [11000/100000], Train Loss: 443,578,346,815,619,072, Val Loss: 4,392,168,796,819,816,448\n",
      "Epoch [12000/100000], Train Loss: 480,886,288,174,546,944, Val Loss: 2,342,653,404,381,184\n",
      "Epoch [13000/100000], Train Loss: 968,843,690,246,144, Val Loss: 445,282,761,637,363,712\n",
      "Epoch [14000/100000], Train Loss: 10,649,954,418,688, Val Loss: 39,219,072,956,628,992\n",
      "Epoch [15000/100000], Train Loss: 6,634,138,018,775,040, Val Loss: 5,800,752,840,704\n",
      "Epoch [16000/100000], Train Loss: 3,716,123,277,476,581,343,232, Val Loss: 8,214,500,226,367,488\n",
      "Epoch [17000/100000], Train Loss: 994,184,265,728,000, Val Loss: 2,314,109,412,509,220,864\n",
      "Epoch [18000/100000], Train Loss: 4,228,068,348,526,592, Val Loss: 38,268,111,362,719,744\n",
      "Epoch [19000/100000], Train Loss: 1,512,390,592,036,864, Val Loss: 1,947,363,941,810,176\n",
      "Epoch [20000/100000], Train Loss: 51,182,987,552,600,621,056, Val Loss: 5,319,785,185,280\n",
      "Epoch [21000/100000], Train Loss: 9,774,517,710,749,696, Val Loss: 1,865,744,530,800,640\n",
      "Epoch [22000/100000], Train Loss: 1,037,868,058,120,552,448, Val Loss: 3,113,269,053,095,936\n",
      "Epoch [23000/100000], Train Loss: 873,389,921,140,736, Val Loss: 546,685,736,905,080,832\n",
      "Epoch [24000/100000], Train Loss: 2,240,542,033,313,792, Val Loss: 670,566,533,038,080\n",
      "Epoch [25000/100000], Train Loss: 1,861,132,004,360,192, Val Loss: 70,745,936,795,533,312\n",
      "Epoch [26000/100000], Train Loss: 7,851,766,993,341,885,972,480, Val Loss: 116,905,968,960,274,432\n",
      "Epoch [27000/100000], Train Loss: 33,022,614,117,023,744, Val Loss: 19,169,719,148,460,638,208\n",
      "Epoch [28000/100000], Train Loss: 326,211,188,293,632, Val Loss: 23,273,748,299,776\n",
      "Epoch [29000/100000], Train Loss: 261,915,125,219,328, Val Loss: 30,860,516,842,799,104\n",
      "Epoch [30000/100000], Train Loss: 3,493,393,357,659,439,104, Val Loss: 102,033,273,126,912\n",
      "Epoch [31000/100000], Train Loss: 65,595,377,654,431,744, Val Loss: 2,646,325,845,819,392\n",
      "Epoch [32000/100000], Train Loss: 11,088,948,428,275,712, Val Loss: 189,731,417,251,381,248\n",
      "Epoch [33000/100000], Train Loss: 41,105,617,846,272, Val Loss: 12,202,577,613,553,664\n",
      "Epoch [34000/100000], Train Loss: 39,445,254,524,370,944, Val Loss: 164,551,415,564,337,152\n",
      "Epoch [35000/100000], Train Loss: 221,726,545,805,312, Val Loss: 226,368,587,797,889,024\n",
      "Epoch [36000/100000], Train Loss: 219,359,063,731,863,552, Val Loss: 6,046,433,484,472,320\n",
      "Epoch [37000/100000], Train Loss: 1,560,235,722,407,936, Val Loss: 2,179,331,098,935,296\n",
      "Epoch [38000/100000], Train Loss: 2,798,479,088,812,032, Val Loss: 7,949,043,867,058,176\n",
      "Epoch [39000/100000], Train Loss: 353,287,688,893,235,200, Val Loss: 2,751,889,587,834,978,304\n",
      "Epoch [40000/100000], Train Loss: 9,342,349,511,491,584, Val Loss: 321,998,302,386,061,312\n",
      "Epoch [41000/100000], Train Loss: 6,265,570,768,977,920, Val Loss: 5,877,492,499,494,090,047,488\n",
      "Epoch [42000/100000], Train Loss: 26,788,338,571,413,553,152, Val Loss: 16,625,208,131,584\n",
      "Epoch [43000/100000], Train Loss: 197,873,941,610,496, Val Loss: 821,788,640,542,720\n",
      "Epoch [44000/100000], Train Loss: 1,679,035,591,557,120, Val Loss: 5,958,508,524,601,344\n",
      "Epoch [45000/100000], Train Loss: 323,188,470,841,344, Val Loss: 108,472,886,573,924,352\n",
      "Epoch [46000/100000], Train Loss: 2,001,884,806,421,413,888, Val Loss: 346,458,066,780,160\n",
      "Epoch [47000/100000], Train Loss: 5,644,049,809,670,144, Val Loss: 1,272,534,076,057,714,688\n",
      "Epoch [48000/100000], Train Loss: 5,577,478,353,453,056, Val Loss: 1,297,434,853,330,911,232\n",
      "Epoch [49000/100000], Train Loss: 671,780,465,278,976, Val Loss: 984,254,368,448,512\n",
      "Epoch [50000/100000], Train Loss: 30,505,396,061,863,936, Val Loss: 764,362,685,285,400,576\n",
      "Epoch [51000/100000], Train Loss: 8,610,564,393,664,512, Val Loss: 16,540,944,480,337,920\n",
      "Epoch [52000/100000], Train Loss: 208,873,218,637,824, Val Loss: 83,814,926,960,434,348,032\n",
      "Epoch [53000/100000], Train Loss: 4,097,559,054,203,748,352, Val Loss: 17,579,851,722,975,608,832\n",
      "Epoch [54000/100000], Train Loss: 268,497,256,250,062,405,632, Val Loss: 1,691,378,656,477,184\n",
      "Epoch [55000/100000], Train Loss: 47,558,248,366,080, Val Loss: 557,906,084,757,504\n",
      "Epoch [56000/100000], Train Loss: 118,109,620,928,512, Val Loss: 14,137,121,077,985,280\n",
      "Epoch [57000/100000], Train Loss: 3,455,392,457,687,040, Val Loss: 3,986,114,855,567,360\n",
      "Epoch [58000/100000], Train Loss: 408,747,021,038,518,272, Val Loss: 81,675,274,236,557,508,214,784\n",
      "Epoch [59000/100000], Train Loss: 42,566,269,819,420,672, Val Loss: 2,292,702,397,857,792\n",
      "Epoch [60000/100000], Train Loss: 511,165,163,634,688, Val Loss: 4,629,349,290,475,520\n",
      "Epoch [61000/100000], Train Loss: 2,335,958,357,820,571,648, Val Loss: 43,978,420,706,607,104\n",
      "Epoch [62000/100000], Train Loss: 343,851,659,165,696, Val Loss: 7,885,392,829,688,578,048\n",
      "Epoch [63000/100000], Train Loss: 8,512,851,680,067,321,856, Val Loss: 2,614,964,799,930,368\n",
      "Epoch [64000/100000], Train Loss: 1,225,246,279,970,324,480, Val Loss: 199,918,358,122,987,520\n",
      "Epoch [65000/100000], Train Loss: 12,463,840,474,169,344, Val Loss: 54,192,561,606,098,944\n",
      "Epoch [66000/100000], Train Loss: 28,034,857,959,424, Val Loss: 3,735,409,885,706,190,848\n",
      "Epoch [67000/100000], Train Loss: 176,984,410,889,056,681,984, Val Loss: 75,426,471,895,629,824\n",
      "Epoch [68000/100000], Train Loss: 103,168,619,143,233,536, Val Loss: 175,461,057,429,504\n",
      "Epoch [69000/100000], Train Loss: 10,901,698,471,329,267,712, Val Loss: 9,049,517,567,508,480\n",
      "Epoch [70000/100000], Train Loss: 1,323,318,996,420,595,286,016, Val Loss: 1,939,472,953,016,057,856\n",
      "Epoch [71000/100000], Train Loss: 381,009,400,954,880, Val Loss: 29,475,041,747,624,110,587,904\n",
      "Epoch [72000/100000], Train Loss: 635,238,145,327,104, Val Loss: 1,649,127,184,138,240\n",
      "Epoch [73000/100000], Train Loss: 5,474,849,573,044,224, Val Loss: 977,013,053,587,456\n",
      "Epoch [74000/100000], Train Loss: 24,398,391,718,768,017,408, Val Loss: 2,379,499,123,507,200\n",
      "Epoch [75000/100000], Train Loss: 1,002,039,303,498,366,976, Val Loss: 1,073,886,376,493,056\n",
      "Epoch [76000/100000], Train Loss: 114,115,888,545,792, Val Loss: 955,312,597,106,688\n",
      "Epoch [77000/100000], Train Loss: 8,705,729,888,256, Val Loss: 436,755,861,864,448\n",
      "Epoch [78000/100000], Train Loss: 105,658,326,188,032, Val Loss: 18,696,340,766,720\n",
      "Epoch [79000/100000], Train Loss: 243,530,521,198,460,928, Val Loss: 293,699,965,463,560,192\n",
      "Epoch [80000/100000], Train Loss: 2,056,267,937,873,920, Val Loss: 199,407,531,892,670,464\n",
      "Epoch [81000/100000], Train Loss: 157,539,501,080,576, Val Loss: 268,094,126,359,052,288\n",
      "Epoch [82000/100000], Train Loss: 124,229,680,889,856, Val Loss: 849,975,539,706,888,192\n",
      "Epoch [83000/100000], Train Loss: 3,953,196,347,162,624, Val Loss: 46,420,558,490,005,143,552\n",
      "Epoch [84000/100000], Train Loss: 50,150,958,725,857,280, Val Loss: 17,051,957,541,732,352\n",
      "Epoch [85000/100000], Train Loss: 43,038,905,200,541,696, Val Loss: 29,503,094,576,381,952\n",
      "Epoch [86000/100000], Train Loss: 13,914,142,482,104,320, Val Loss: 7,462,646,336,978,944\n",
      "Epoch [87000/100000], Train Loss: 55,218,635,031,189,651,456, Val Loss: 568,423,083,933,696\n",
      "Epoch [88000/100000], Train Loss: 192,091,388,903,424, Val Loss: 10,351,524,843,022,712,832\n",
      "Epoch [89000/100000], Train Loss: 7,475,609,622,020,096, Val Loss: 1,731,616,326,025,216\n",
      "Epoch [90000/100000], Train Loss: 19,579,745,075,200, Val Loss: 2,245,158,720,503,808\n",
      "Epoch [91000/100000], Train Loss: 71,449,775,702,016, Val Loss: 17,881,880,970,055,909,376\n",
      "Epoch [92000/100000], Train Loss: 446,185,663,889,408, Val Loss: 331,243,648,987,430,912\n",
      "Epoch [93000/100000], Train Loss: 2,750,087,692,288,000, Val Loss: 13,776,834,525,134,848\n",
      "Epoch [94000/100000], Train Loss: 608,796,984,475,648, Val Loss: 365,542,536,258,781,184\n",
      "Epoch [95000/100000], Train Loss: 6,263,882,309,959,680, Val Loss: 107,936,989,416,909,701,120\n",
      "Epoch [96000/100000], Train Loss: 5,927,945,000,452,096, Val Loss: 592,397,255,835,648\n",
      "Epoch [97000/100000], Train Loss: 192,853,446,158,712,832, Val Loss: 1,307,783,852,982,272\n",
      "Epoch [98000/100000], Train Loss: 128,472,999,526,400, Val Loss: 7,925,884,866,527,232\n",
      "Epoch [99000/100000], Train Loss: 73,501,469,835,264, Val Loss: 32,689,350,424,657,920\n",
      "Epoch [100000/100000], Train Loss: 217,389,752,909,824, Val Loss: 1,414,354,473,844,736\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    # Generate random 5x5 matrices\n",
    "    if distribution == \"gaussian\":\n",
    "        A = np.random.randn(batch_size, 5, 5)\n",
    "        A = np.array(coeff_upper / math.sqrt(3.0) * A)\n",
    "    elif distribution == \"uniform\":\n",
    "        A = np.random.rand(batch_size, 5, 5)\n",
    "        A = np.array(max_coeff * (2 * A - 1))\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported distribution\")\n",
    "\n",
    "    \n",
    "    # Calculate exp(A)\n",
    "    A_exp = matrix_exponential(A)\n",
    "    \n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    A_tensor = torch.FloatTensor(A).view(batch_size, -1).to(device)\n",
    "    A_exp_tensor = torch.FloatTensor(A_exp).view(batch_size, -1).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(A_tensor)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, A_exp_tensor)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation step\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if distribution == \"gaussian\":\n",
    "                A_val = np.random.randn(batch_size, 5, 5)\n",
    "                A_val = np.array(coeff_upper / math.sqrt(3.0) * A_val)\n",
    "            elif distribution == \"uniform\":\n",
    "                A_val = np.random.rand(batch_size, 5, 5)\n",
    "                A_val = np.array(max_coeff * (2 * A_val - 1))\n",
    "            else:\n",
    "                raise TypeError(\"Unsupported distribution\")\n",
    "            # A_val = np.random.randn(batch_size, 5, 5)\n",
    "            A_exp_val = matrix_exponential(A_val)\n",
    "            A_val_tensor = torch.FloatTensor(A_val).view(batch_size, -1).to(device)\n",
    "            A_exp_val_tensor = torch.FloatTensor(A_exp_val).view(batch_size, -1).to(device)\n",
    "            val_output = model(A_val_tensor)\n",
    "            val_loss = criterion(val_output, A_exp_val_tensor)\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "        # print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():,.0f}, Val Loss: {val_loss.item():,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06dec0b-af74-41de-8f90-bd21bde35fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), os.path.join(save_dir, 'matrix_exp_model.pth'))\n",
    "\n",
    "# Save loss lists\n",
    "with open(os.path.join(save_dir, 'losses.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Epoch', 'Train Loss', 'Validation Loss'])\n",
    "    for i, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses)):\n",
    "        writer.writerow([i*100, train_loss, val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af594b89-db17-4df0-b487-6f9f2596515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 596.6367\n",
      "\n",
      "Example 1:\n",
      "Input matrix A:\n",
      "[[-0.84518283 -0.05493905 -1.23835785  1.50580414  0.08394291]\n",
      " [ 0.18450781 -0.5815779   1.11920838  0.28610345 -0.99999603]\n",
      " [-1.35079053 -1.6066835   1.82087014  0.72972418  0.02872044]\n",
      " [-0.69732303 -0.20768064  0.13489679 -1.36292633  0.33090042]\n",
      " [-0.1898658  -1.27170226  0.5693403  -1.29001019  1.00780285]]\n",
      "Actual exp(A):\n",
      "[[ 1.34059342  1.19356223 -2.4405933   0.38999619 -0.17754486]\n",
      " [-0.94518732 -0.10167716  2.27026054  0.66030535 -1.00384153]\n",
      " [-3.20839448 -4.35936115  6.31928505 -0.75444431  2.04853278]\n",
      " [-0.47484715 -0.59622215  0.66733019 -0.09432515  0.54428514]\n",
      " [-0.37326733 -2.37319507  0.78480598 -1.78276098  3.70516644]]\n",
      "Predicted exp(A):\n",
      "[[25.769173    1.0139344   0.6786248   1.8967853  -0.6312778 ]\n",
      " [-0.51845074 21.822561   -3.1109998  -4.103498    0.47300094]\n",
      " [ 1.8668433   0.36196858 25.744267    0.16746205 -1.6654083 ]\n",
      " [ 4.970542    2.7029173  -3.1128755  25.71772     1.3305064 ]\n",
      " [-0.9797016  -5.670396   -2.3350637   3.3942792  25.038788  ]]\n",
      "\n",
      "Example 2:\n",
      "Input matrix A:\n",
      "[[-1.28011503  1.34905665  0.72670022  0.21405606 -0.78001297]\n",
      " [ 0.36273457  2.58789797 -0.41600264 -0.32985275  0.57851736]\n",
      " [-1.74237641 -1.88112402  2.02467719 -1.15575517  0.49187388]\n",
      " [-0.47542044  0.79068834 -0.48251933  0.70693578 -0.93935435]\n",
      " [-0.70682732  1.27273196 -1.08112091 -0.63807754  1.07344556]]\n",
      "Actual exp(A):\n",
      "[[ -0.21982535   0.54517952   1.44718575  -0.78557284   0.28195529]\n",
      " [  3.36721807  23.40473576  -6.21254715  -1.36890291   4.15512305]\n",
      " [ -5.93313926 -26.00589605   9.33893751  -3.70091395   1.42769123]\n",
      " [  0.87881204   4.98019797  -1.37991617   2.83951681  -2.01147717]\n",
      " [  3.29311515  19.12056224  -8.1539423   -0.36923485   4.63095582]]\n",
      "Predicted exp(A):\n",
      "[[30.766098    1.1316507   0.8241864   2.347884   -0.9253657 ]\n",
      " [-0.65693367 26.385029   -3.9414175  -5.0532846   0.8130849 ]\n",
      " [ 2.357954    0.32006055 30.852095    0.05195876 -2.0475445 ]\n",
      " [ 5.7518415   3.0741353  -3.9431143  30.893017    1.7477016 ]\n",
      " [-1.1001446  -6.6070414  -2.9086542   4.006848   29.840359  ]]\n",
      "\n",
      "Example 3:\n",
      "Input matrix A:\n",
      "[[ 0.6990486   0.72844746  0.38389251 -0.19268528 -0.68461611]\n",
      " [-0.26352386 -1.12685432  0.19220804  0.57522869 -0.33078996]\n",
      " [ 1.03373371  0.6137969   0.20752844 -1.53031563 -0.98637434]\n",
      " [ 0.65891479  1.58379604  0.45018851  0.52490753 -1.32217997]\n",
      " [-3.66669882 -0.7154331   0.4146966   0.8773461   1.32347578]]\n",
      "Actual exp(A):\n",
      "[[  5.60720841   1.23745694   0.50255547  -1.5025336   -2.55834536]\n",
      " [  1.84988912   0.94757518   0.19960578  -0.09819629  -1.35189793]\n",
      " [  2.94778052  -0.08890473   0.93365891  -2.78357946  -0.96152494]\n",
      " [  9.25885705   3.25665197   0.82898368  -0.55232452  -5.98360191]\n",
      " [-11.5231248   -2.27214298  -0.09047965   3.04824032   6.06727625]]\n",
      "Predicted exp(A):\n",
      "[[34.045486    1.102659    1.2448118   2.338711   -1.0799749 ]\n",
      " [-0.6176801  28.41056    -4.1809163  -5.481541    0.71468973]\n",
      " [ 2.6797364   0.54211664 33.454605   -0.23511261 -2.3463979 ]\n",
      " [ 6.258117    3.562318   -4.4135647  33.701725    1.9761124 ]\n",
      " [-1.4934881  -7.2236166  -3.0600114   4.3503385  32.668488  ]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate test matrices\n",
    "    num_test = 1000\n",
    "\n",
    "    if distribution == \"gaussian\":\n",
    "        A_test = np.random.randn(num_test, 5, 5)\n",
    "        A = np.array(coeff_upper / math.sqrt(3.0) * A)\n",
    "    elif distribution == \"uniform\":\n",
    "        A_test = np.random.rand(num_test, 5, 5)\n",
    "        A = np.array(max_coeff * (2 * A - 1))\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported distributon.\")\n",
    "\n",
    "    # clip\n",
    "    A = np.clip(A * coeff_upper, coeff_lower, coeff_upper)\n",
    "    \n",
    "    A_exp_test = matrix_exponential(A_test)\n",
    "    \n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    A_test_tensor = torch.FloatTensor(A_test).view(num_test, -1).to(device)\n",
    "    A_exp_test_tensor = torch.FloatTensor(A_exp_test).view(num_test, -1).to(device)\n",
    "    \n",
    "    # Get model predictions\n",
    "    predictions = model(A_test_tensor)\n",
    "    \n",
    "    # Compute test loss\n",
    "    test_loss = criterion(predictions, A_exp_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    \n",
    "    # Compare a few results\n",
    "    for i in range(3):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(\"Input matrix A:\")\n",
    "        print(A_test[i])\n",
    "        print(\"Actual exp(A):\")\n",
    "        print(A_exp_test[i])\n",
    "        print(\"Predicted exp(A):\")\n",
    "        print(predictions[i].view(5, 5).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070161c7-cec1-4d6d-9041-78ac3ac696bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test data and evaluations\n",
    "with open(os.path.join(save_dir, 'test_data_and_evaluations.csv'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Test Matrix', 'Actual exp(A)', 'Predicted exp(A)', 'Error'])\n",
    "    for i in range(num_test):\n",
    "        pred = predictions[i].cpu().numpy().flatten()\n",
    "        actual = A_exp_test[i].flatten()\n",
    "        writer.writerow([\n",
    "            A_test[i].flatten().tolist(),\n",
    "            actual.tolist(),\n",
    "            pred.tolist(),\n",
    "            (pred - actual).tolist()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b9a87d3-6aec-47d9-8089-f1abee44e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_losses)=100000\n",
      "len(val_losses)=100\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_losses)=}\\n{len(val_losses)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e6af7aa-ec5b-4d8b-beb2-4dfe387badb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "# 1. Training and Validation Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(range(99, len(train_losses), 1000), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91276c0f-830d-44f3-b67d-6d9dfe795b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Histogram of Errors\n",
    "errors = (predictions - A_exp_test_tensor).cpu().numpy().flatten()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(errors, bins=50)\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Errors')\n",
    "plt.savefig(os.path.join(save_dir, 'error_histogram.png'))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf46488-513f-4913-9336-6d81c56e81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predicted vs Actual Values\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(A_exp_test_tensor.cpu().numpy().flatten(), predictions.cpu().numpy().flatten(), alpha=0.5)\n",
    "plt.plot([A_exp_test_tensor.cpu().numpy().min(), A_exp_test_tensor.cpu().numpy().max()], \n",
    "         [A_exp_test_tensor.cpu().numpy().min(), A_exp_test_tensor.cpu().numpy().max()], \n",
    "         'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.savefig(os.path.join(save_dir, 'predicted_vs_actual.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ed70a78-bbf1-44be-8a0b-6756bdbe4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Example Comparison\n",
    "example_idx = 0\n",
    "actual = A_exp_test[example_idx]\n",
    "predicted = predictions[example_idx].view(5, 5).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fbb3f4b-3fbe-44d8-bdd9-2d55512f0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ac01199b460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "im1 = ax1.imshow(actual, cmap='viridis')\n",
    "ax1.set_title('Actual exp(A)')\n",
    "plt.colorbar(im1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07869f14-7e6b-45b0-91fd-4dc9c21d6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ac00ef667a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im2 = ax2.imshow(predicted, cmap='viridis')\n",
    "ax2.set_title('Predicted exp(A)')\n",
    "plt.colorbar(im2, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10a85347-6dba-4150-b4d6-d2350e634b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizations have been saved as PNG files.\n"
     ]
    }
   ],
   "source": [
    "plt.savefig(os.path.join(save_dir, 'example_comparison.png'))\n",
    "plt.close()\n",
    "\n",
    "print(\"Visualizations have been saved as PNG files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d37e5e-001a-42c1-9729-28360ab9468f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6445bdf4-adaa-4ce0-9b9a-a6f93b53730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rahulpadmanabhan/Development/ws1/masters_thesis_2/LAWT/notebooks/matrix_exp_results/202405161723781116'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c13e4f-5687-48dc-804e-31055985a772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
