{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92608fc3-14be-4de6-99c3-0bec3b1a8f5c",
   "metadata": {},
   "source": [
    "### Different params for transformer encoder. Increase # of heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e1ac83-c0fc-4879-bfe3-c710ce17ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "\n",
    "from scipy.linalg import expm, hadamard, signm\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import logging\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb49572a-0f65-49c8-b78d-d7e77a717841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:40:15,629 - datagenerator - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/rahulpadmanabhan/Development/ws1/masters_thesis_2/LAWT/src/neuralnet')\n",
    "# sys.path.insert(0, '/home/rahulpadmanabhan/Development/ws1/masters_thesis_2/LAWT/src/')\n",
    "import datagenerator\n",
    "from models import MatrixFunctionTransformer\n",
    "from common import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc6646f-fa77-45ff-b7f3-713f2d78116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc89b32-ecf7-4a2b-895c-14bda8b1e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad42912-31d6-4eb2-9d28-14876a6f506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3af2d614-aa01-42e7-9200-ffe7d9ff0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:40:17,200 - root - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaca555-663b-416d-9591-0822607c8f4d",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7add3eb4-afff-4899-99fd-613b0849c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 5\n",
    "operation = \"sin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee6981e-0423-4a2f-9983-46dec48f4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 2**15  # 16384\n",
    "k_values = range(5, 19)\n",
    "train_samples = [32768*2]\n",
    "dim = dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800a058e-dc61-4fc2-83fe-10066601008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:43:36,186 - root - INFO - train_samples=[65536], test_samples=32768\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"{train_samples=}, {test_samples=}\")\n",
    "\n",
    "relative_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f07215c-f4d1-4e73-9a67-44e421e4a8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:45:40,108 - root - INFO - models_lst=['/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/layers_16/sin_model_32768.pth']\n",
      "\n",
      "train_lst=['/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/train/train_dataset_32768.pt']\n",
      "\n",
      "test_lst=['/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/test/test_dataset_32768.pt']\n"
     ]
    }
   ],
   "source": [
    "train_vals = [3*16384 - 16384]\n",
    "layer=16\n",
    "models_lst = [*map(lambda x: os.path.join(save_dir, f\"dim_{dim}\", f'layers_{layer}', f'{operation}_model_{str(x)}.pth'), train_vals)]\n",
    "train_lst = [*map(lambda x: os.path.join(save_dir, f\"dim_{dim}\", \"train\", f'train_dataset_{str(x)}.pt'), train_vals)]\n",
    "test_lst = [*map(lambda x: os.path.join(save_dir, f\"dim_{dim}\", \"test\", f'test_dataset_{str(x)}.pt'), train_vals)]\n",
    "\n",
    "logger.info(f\"{models_lst=}\\n\\n{train_lst=}\\n\\n{test_lst=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aa550b0-941a-495c-9af2-d8c4ed6597f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/layers_16/sin_model_32768.pth'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a1d8027-f21c-4123-854e-14eee7c73fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 19:45:41,828 - root - INFO - MatrixFunctionTransformer(\n",
      "  (encoder1): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=5, out_features=5, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=5, out_features=20, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=20, out_features=5, bias=True)\n",
      "        (norm1): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-15): 16 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=5, out_features=5, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=5, out_features=20, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=20, out_features=5, bias=True)\n",
      "        (norm1): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dim=5\n",
    "d_model = dim*dim\n",
    "# Ensure d_model is divisible by nhead\n",
    "nhead = dim\n",
    "d_model = (dim // nhead) * nhead\n",
    "# Load the saved model\n",
    "model = MatrixFunctionTransformer(d_model, dim, 16).to(device)\n",
    "model.load_state_dict(torch.load(models_lst[0]))\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "324558c8-0bd0-4ac2-acd6-9d92fb88b717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatrixFunctionTransformer(\n",
       "  (encoder1): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=5, out_features=5, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=5, out_features=20, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=20, out_features=5, bias=True)\n",
       "        (norm1): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder2): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=5, out_features=5, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=5, out_features=20, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=20, out_features=5, bias=True)\n",
       "        (norm1): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models_lst[]\n",
    "dim=5\n",
    "d_model = dim*dim\n",
    "# Ensure d_model is divisible by nhead\n",
    "nhead = dim\n",
    "d_model = (dim // nhead) * nhead\n",
    "model = MatrixFunctionTransformer(d_model, dim, 16).to(device)\n",
    "model.load_state_dict(torch.load(models_lst[0]))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f2f42d4-2c43-4a3b-a8de-da955db053a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_path = '/mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/layers_16/test/test_dataset_32768.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe8537e7-3081-4f53-908d-e533a97af984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulpadmanabhan/Development/envs/venv310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "2024-09-10 19:50:51,066 - root - INFO - Loaded model: /mnt/wd_2tb/thesis_transformers/experiments/transformer_wo_embedding/sin/encoder_20240909235033/dim_5/layers_16/sin_model_32768.pth\n",
      "2024-09-10 19:50:51,066 - root - INFO - len(test_dataset)=32768\n",
      "2024-09-10 19:50:51,067 - root - INFO - Starting to predict values in the test_dataset\n",
      "2024-09-10 19:50:51,068 - root - INFO - dim=5\n",
      "2024-09-10 19:56:37,194 - root - INFO - \n",
      "predicted.shape=torch.Size([32768, 5, 5])\n",
      "actuals.shape=torch.Size([32768, 5, 5])\n",
      "2024-09-10 19:56:37,203 - root - INFO - np_predicted.dtype=dtype('float64'),np_actuals.dtype=dtype('float64')\n",
      "2024-09-10 19:56:37,223 - root - INFO - mu=-0.11825660570541068,sigma=0.26098810689990776\n",
      "2024-09-10 19:56:37,223 - root - INFO - y_main=0.7616288637091487,u_shaded=0.41759499742078565,l_shaded=1.389093570607069\n",
      "2024-09-10 19:56:37,223 - root - INFO - x_raw.shape=(819200,), y_raw.shape=(819200,)\n"
     ]
    }
   ],
   "source": [
    "mu_lst = []\n",
    "sigma_lst = []\n",
    "y_main_lst = []\n",
    "u_shaded_lst = []\n",
    "l_shaded_lst = []\n",
    "dim=5\n",
    "\n",
    "d_model = dim*dim\n",
    "# Ensure d_model is divisible by nhead\n",
    "nhead = dim\n",
    "d_model = (dim // nhead) * nhead\n",
    "model = MatrixFunctionTransformer(d_model, dim, 16).to(device)\n",
    "model.load_state_dict(torch.load(models_lst[0]))\n",
    "model.eval()\n",
    "\n",
    "# Loading the test dataset\n",
    "test_dataset = torch.load(test_ds_path)\n",
    "\n",
    "logger.info(f\"Loaded model: {models_lst[0]}\")\n",
    "logger.info(f\"{len(test_dataset)=}\")\n",
    "\n",
    "actuals = []\n",
    "predicted = []\n",
    "\n",
    "logger.info(f\"Starting to predict values in the test_dataset\")\n",
    "with torch.no_grad():\n",
    "    logger.info(f\"{dim=}\")\n",
    "    for x, y in test_dataset:\n",
    "        x = x.view(-1, dim, dim).to(device).to(torch.float64)\n",
    "        y = y.view(-1, dim, dim).to(device).to(torch.float64)\n",
    "        # if dim == 1:\n",
    "            # predicted.append(model(x.view(-1, 1).to(device).to(torch.float64)))\n",
    "            # actuals.append(y.view(-1,1).to(device).to(torch.float64))\n",
    "        # else:\n",
    "            # predicted.append(model(x.view(1, dim*dim).to(device).to(torch.float64)))\n",
    "            # actuals.append(y.view(1, dim*dim).to(device).to(torch.float64))\n",
    "                \n",
    "        predicted.append(model(x))\n",
    "        actuals.append(y)\n",
    "        \n",
    "    predicted = torch.cat(predicted, 0)\n",
    "    actuals = torch.cat(actuals, 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f032522-16bc-45c7-be7f-49a9472e1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"\\n{predicted.shape=}\\n{actuals.shape=}\")\n",
    "\n",
    "np_predicted = predicted.view(-1).cpu().numpy()\n",
    "np_actuals = actuals.view(-1).cpu().numpy()\n",
    "\n",
    "logger.info(f\"{np_predicted.dtype=},{np_actuals.dtype=}\")\n",
    "\n",
    "# mu = np.mean(np.log10(np_predicted))\n",
    "y_is = np.abs(np_predicted - np_actuals)/(np.abs(np_actuals + 1e-6) ) # did this in a hurry, double check denominator\n",
    "mu = np.mean(np.log10(y_is))\n",
    "sigma = (np_predicted.shape[0] -1)**-1 * np.sum((np.log10(y_is) - mu)**2)\n",
    "\n",
    "y_main = 10**mu \n",
    "\n",
    "u_shaded = 10**(mu - sigma)\n",
    "l_shaded = 10**(mu + sigma)\n",
    "\n",
    "logger.info(f\"{mu=},{sigma=}\")\n",
    "logger.info(f\"{y_main=},{u_shaded=},{l_shaded=}\")\n",
    "\n",
    "x_raw = np.repeat(train_vals[0], np_predicted.shape[0])\n",
    "y_raw = np_actuals\n",
    "\n",
    "logger.info(f\"{x_raw.shape=}, {y_raw.shape=}\")\n",
    "\n",
    "mu_lst.append(mu)\n",
    "sigma_lst.append(sigma)\n",
    "y_main_lst.append(y_main)\n",
    "u_shaded_lst.append(u_shaded)\n",
    "l_shaded_lst.append(l_shaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef6d5bf8-37e0-4928-a13f-ab5d68026da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11825660570541068]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_lst # Relative error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd139adf-f0f7-4882-a37f-d98ba0e719b7",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Increasing Epochs and heads of attention has a better relative error. Went to only ~55% compared to over 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cdb518-0b9f-42e1-b33e-9299d90e6566",
   "metadata": {},
   "source": [
    "#### Checking an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c18d4ff-15bd-4ebf-92da-a7caf56b7357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5669,  0.0280,  0.1150, -0.3110, -0.3589],\n",
       "        [-0.5557,  0.0029,  0.0847,  0.0966, -0.4501],\n",
       "        [-0.1266, -0.0240, -0.0596,  0.1872,  0.5718],\n",
       "        [-0.1165,  0.0226, -0.0491, -0.1236,  0.5633],\n",
       "        [ 0.3743,  0.0626, -0.0006, -0.4007, -0.2837]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4069e292-b97a-4d0e-9bc0-09139ec4c387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2439, -1.0375,  1.1604, -0.7223, -1.3062],\n",
       "        [-0.2895, -0.2425,  0.5196,  0.6788, -0.3176],\n",
       "        [-0.2343,  0.2411, -0.1000, -0.1480,  1.2491],\n",
       "        [ 0.0095, -0.0631, -1.2723, -0.8501,  1.0528],\n",
       "        [ 0.7948,  0.6903, -0.4627, -0.8783, -0.3440]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57a8d2-ad2c-45f8-9239-4974d37812c9",
   "metadata": {},
   "source": [
    "### Relative Error Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebfd1934-a09b-4c76-8d37-d0c708521101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 20:16:41,642 - root - INFO - Relative error:relative_error.item()=0.8466582103921876\n"
     ]
    }
   ],
   "source": [
    "relative_error = torch.mean(torch.abs(torch.norm(predicted - actuals, p='fro', dim=(1,2)) / torch.norm(actuals, p='fro', dim=(1,2))))\n",
    "logger.info(f\"Relative error:{relative_error.item()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b33a7e6-4f3e-47af-9091-dea3a190e29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0723, device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log10(relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c5666fd-9a5d-487c-b3df-b8b155f7bc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8474225179233051"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**-0.0719"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4223f-9ae3-4228-b416-32cbb9311183",
   "metadata": {},
   "source": [
    "#### Number of accurate samples with a tolerance of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d87256c4-3ba4-4d14-b1e8-c4c5378fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculating\n",
    "relative_error = torch.norm(predicted - actuals, p='fro', dim=(-2,-1)) / torch.norm(actuals, p='fro', dim=(-2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f03a65f4-7fb2-4e85-a24c-89e4a599989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb7dd019-d85b-49ca-8cd8-a1a3783d415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 20:18:11,725 - root - INFO - Number of accurate samples: 0/32768\n",
      "2024-09-10 20:18:11,726 - root - INFO - Mean relative error: 0.8467\n",
      "2024-09-10 20:18:11,727 - root - INFO - Standard deviation of relative error: 0.0635\n"
     ]
    }
   ],
   "source": [
    "# Number of accurate samples\n",
    "accurate_samples = (relative_error <= tolerance).sum().item()\n",
    "total_samples = relative_error.size(0)\n",
    "logger.info(f\"Number of accurate samples: {accurate_samples}/{total_samples}\")\n",
    "\n",
    "# Calculate the mean and standard deviation of the relative error\n",
    "mean_relative_error = relative_error.mean().item()\n",
    "std_relative_error = relative_error.std().item()\n",
    "logger.info(f\"Mean relative error: {mean_relative_error:.4f}\")\n",
    "logger.info(f\"Standard deviation of relative error: {std_relative_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de152a33-1a03-4450-9ab6-ee868670d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
